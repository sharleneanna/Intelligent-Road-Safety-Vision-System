{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "KxZAbnoLD-l1",
        "outputId": "88de022f-acca-4d63-bc39-5722280f6703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
            "üì¶ Downloading IDD via KaggleHub‚Ä¶\n",
            "Using Colab cache for faster access to the 'new-idd-dataset' dataset.\n",
            "‚úî Dataset downloaded to: /kaggle/input/new-idd-dataset\n",
            "üìÅ Copying IDD dataset to working directory...\n",
            "‚úî Dataset copied successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batch Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:08<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî Batch Evaluation Complete: /content/autosafedrive_outputs/eval_20251116_153704.csv\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://76519c2cd375d615c7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://76519c2cd375d615c7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ===============================================================\n",
        "# AutoSafeDrive ADAS ‚Äî FINAL SUBMISSION (CLEAN VERSION)\n",
        "# Real-Time Object Detection + Risk Estimation + Gradio Demo\n",
        "# ===============================================================\n",
        "\n",
        "!pip install -q ultralytics gradio kagglehub opencv-python-headless tqdm pandas matplotlib\n",
        "\n",
        "# ===============================\n",
        "# IMPORTS\n",
        "# ===============================\n",
        "import os, random, shutil, traceback\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import cv2, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "import gradio as gr\n",
        "\n",
        "try:\n",
        "    import kagglehub\n",
        "    _KH = True\n",
        "except:\n",
        "    _KH = False\n",
        "\n",
        "# ===============================\n",
        "# PATHS\n",
        "# ===============================\n",
        "ROOT = \"/content\"\n",
        "DATA_ROOT = f\"{ROOT}/data/idd\"\n",
        "TEST_DIR = f\"{DATA_ROOT}/test/images\"\n",
        "OUT_DIR = f\"{ROOT}/autosafedrive_outputs\"\n",
        "\n",
        "Path(TEST_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ===============================\n",
        "# LOAD YOLOv8 MODEL\n",
        "# ===============================\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "names = model.model.names\n",
        "print(\"Model Loaded:\", names)\n",
        "\n",
        "# ===============================\n",
        "# ADAS CONFIG\n",
        "# ===============================\n",
        "INTEREST = {\"car\",\"bus\",\"truck\",\"motorcycle\",\"bicycle\",\"person\",\"traffic light\"}\n",
        "VULNERABLE = {\"person\",\"bicycle\",\"motorcycle\"}\n",
        "\n",
        "CONF_THRESH = 0.25\n",
        "MIN_BOX_H = 10\n",
        "\n",
        "RISK_SAFE = 35\n",
        "RISK_CAUTION = 65\n",
        "\n",
        "# ===============================\n",
        "# HELPERS\n",
        "# ===============================\n",
        "def risk_color(r):\n",
        "    return (0,200,0) if r < RISK_SAFE else (0,215,255) if r < RISK_CAUTION else (0,0,230)\n",
        "\n",
        "def status_from_risk(r):\n",
        "    return (\"SAFE\",(0,200,0)) if r < RISK_SAFE else (\"CAUTION\",(0,215,255)) if r < RISK_CAUTION else (\"DANGER\",(0,0,230))\n",
        "\n",
        "def draw_banner(img, text, color):\n",
        "    (tw,th),_ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)\n",
        "    cv2.rectangle(img,(10,10),(tw+30,th+30),color,-1)\n",
        "    cv2.putText(img,text,(18,10+th+10),cv2.FONT_HERSHEY_SIMPLEX,0.9,(0,0,0),2)\n",
        "\n",
        "def compute_risk(box, img_h, cls):\n",
        "    x1,y1,x2,y2 = box\n",
        "    proximity = (y2 - y1) / img_h * 100\n",
        "    vuln = 15 if cls in VULNERABLE else 0\n",
        "    risk = proximity * 0.6 + vuln\n",
        "    return float(np.clip(risk, 0, 100))\n",
        "\n",
        "# ===============================\n",
        "# DOWNLOAD DATASET (KaggleHub)\n",
        "# ===============================\n",
        "def download_idd():\n",
        "    if not _KH:\n",
        "        print(\"‚ö†Ô∏è KaggleHub unavailable ‚Äî please upload dataset manually.\")\n",
        "        return None\n",
        "\n",
        "    print(\"üì¶ Downloading IDD via KaggleHub‚Ä¶\")\n",
        "    try:\n",
        "        path = kagglehub.dataset_download(\"mitanshuchakrawarty/new-idd-dataset\")\n",
        "        print(\"‚úî Dataset downloaded to:\", path)\n",
        "        return path\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è KaggleHub download failed.\")\n",
        "        return None\n",
        "\n",
        "# ===============================\n",
        "# FIX ‚Äî COPY DATASET TO WORKING DIR\n",
        "# ===============================\n",
        "def copy_idd_to_working():\n",
        "    SRC = \"/kaggle/input/new-idd-dataset\"\n",
        "    if not os.path.exists(SRC):\n",
        "        print(\"‚ö†Ô∏è Dataset path not found:\", SRC)\n",
        "        return False\n",
        "\n",
        "    print(\"üìÅ Copying IDD dataset to working directory...\")\n",
        "    for root, _, files in os.walk(SRC):\n",
        "        for f in files:\n",
        "            if f.lower().endswith((\"jpg\",\"jpeg\",\"png\")):\n",
        "                src = os.path.join(root, f)\n",
        "                dst = os.path.join(DATA_ROOT, f)\n",
        "                shutil.copy(src, dst)\n",
        "    print(\"‚úî Dataset copied successfully.\")\n",
        "    return True\n",
        "\n",
        "# ===============================\n",
        "# PREPARE TEST SUBSET\n",
        "# ===============================\n",
        "def prepare_test_subset(take_n=30):\n",
        "    all_imgs = [\n",
        "        os.path.join(DATA_ROOT, f)\n",
        "        for f in os.listdir(DATA_ROOT)\n",
        "        if f.lower().endswith((\"jpg\",\"jpeg\",\"png\"))\n",
        "    ]\n",
        "\n",
        "    if len(all_imgs) == 0:\n",
        "        raise RuntimeError(\"‚ùå No images found after dataset copy.\")\n",
        "\n",
        "    random.shuffle(all_imgs)\n",
        "    picks = all_imgs[:take_n]\n",
        "\n",
        "    for p in picks:\n",
        "        dst = os.path.join(TEST_DIR, os.path.basename(p))\n",
        "        shutil.copy(p, dst)\n",
        "\n",
        "    return sorted(os.listdir(TEST_DIR))\n",
        "\n",
        "# ===============================\n",
        "# ANNOTATION FUNCTION\n",
        "# ===============================\n",
        "def annotate_image(img):\n",
        "    res = model(img, conf=CONF_THRESH, verbose=False)[0]\n",
        "    h,w = img.shape[:2]\n",
        "    vis = img.copy()\n",
        "    risks = []\n",
        "\n",
        "    if res.boxes is not None:\n",
        "        bx = res.boxes.xyxy.cpu().numpy()\n",
        "        cl = res.boxes.cls.cpu().numpy().astype(int)\n",
        "        cf = res.boxes.conf.cpu().numpy()\n",
        "\n",
        "        for (x1,y1,x2,y2), cid, conf in zip(bx, cl, cf):\n",
        "            cls = names[cid]\n",
        "            if cls not in INTEREST: continue\n",
        "            if (y2-y1) < MIN_BOX_H: continue\n",
        "\n",
        "            risk = compute_risk([x1,y1,x2,y2], h, cls)\n",
        "            risks.append(risk)\n",
        "\n",
        "            color = risk_color(risk)\n",
        "            cv2.rectangle(vis,(int(x1),int(y1)),(int(x2),int(y2)),color,2)\n",
        "            cv2.putText(vis,f\"{cls} {int(conf*100)}% R{int(risk)}%\",\n",
        "                        (int(x1),max(20,int(y1)-5)),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX,0.6,color,2)\n",
        "\n",
        "    avg = float(np.mean(risks)) if risks else 0.0\n",
        "    status, color = status_from_risk(avg)\n",
        "    draw_banner(vis, f\"AVG {avg:.1f}%  {status}\", color)\n",
        "\n",
        "    return vis, avg, status\n",
        "\n",
        "# ===============================\n",
        "# BATCH EVALUATION\n",
        "# ===============================\n",
        "def batch_eval():\n",
        "    files = sorted(os.listdir(TEST_DIR))\n",
        "    results = []\n",
        "\n",
        "    for fn in tqdm(files, desc=\"Batch Evaluating\"):\n",
        "        img = cv2.imread(os.path.join(TEST_DIR, fn))\n",
        "        vis, avg, status = annotate_image(img)\n",
        "\n",
        "        cv2.imwrite(os.path.join(OUT_DIR, f\"annot_{fn}\"), vis)\n",
        "        results.append({\"image\":fn,\"avg_risk\":round(avg,2),\"status\":status})\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    csv_path = os.path.join(OUT_DIR, f\"eval_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\")\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.hist(df[\"avg_risk\"], bins=10, color=\"skyblue\", edgecolor=\"black\")\n",
        "    plt.title(\"Risk Distribution\")\n",
        "    plt.savefig(os.path.join(OUT_DIR,\"risk_hist.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    return df, csv_path\n",
        "\n",
        "# ===============================\n",
        "# GRADIO DEMO\n",
        "# ===============================\n",
        "def analyze_demo(pil_img):\n",
        "    bgr = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
        "    vis, avg, status = annotate_image(bgr)\n",
        "    return cv2.cvtColor(vis, cv2.COLOR_BGR2RGB), f\"Avg Risk: {avg:.1f}% | {status}\"\n",
        "\n",
        "def launch_demo():\n",
        "    with gr.Blocks() as app:\n",
        "        gr.Markdown(\"## üöó AutoSafeDrive ADAS Demo\")\n",
        "        img_in = gr.Image(type=\"pil\")\n",
        "        img_out = gr.Image()\n",
        "        status_out = gr.Textbox()\n",
        "        btn = gr.Button(\"Analyze\")\n",
        "        btn.click(analyze_demo, inputs=[img_in], outputs=[img_out,status_out])\n",
        "    app.launch(share=True)\n",
        "\n",
        "# ===============================\n",
        "# MAIN EXECUTION\n",
        "# ===============================\n",
        "try:\n",
        "    download_idd()             # Download dataset\n",
        "    copy_idd_to_working()      # Copy dataset to /content/data/idd\n",
        "    prepare_test_subset(20)    # Prepare subset\n",
        "    df, csv_path = batch_eval()\n",
        "    print(\"‚úî Batch Evaluation Complete:\", csv_path)\n",
        "    launch_demo()              # Start Gradio demo\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"‚ùå ERROR OCCURRED:\")\n",
        "    traceback.print_exc()\n",
        "    print(\"Please upload images manually to:\", TEST_DIR)\n"
      ]
    }
  ]
}